{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Scene\n",
    "\n",
    "Imagine you are working for a social media company. The company is concerned with the growing amount of fake news circulatng on it's platform. They have assigned you to investigate how fake news can be recognized and create a method of identifying it. Let's work through this problem together, first by exploring and cleaning the data and then working to classify fake vs factual news stories. We'll also create some plots of our outputs and discuss how we would communicate our findings to stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot options\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "default_plot_colour = \"#00bfbf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"fake_news_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>fake_or_factual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>HOLLYWEIRD LIB SUSAN SARANDON Compares Muslim ...</td>\n",
       "      <td>There are two small problems with your analogy...</td>\n",
       "      <td>Dec 30, 2015</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Elijah Cummings Called Trump Out To His Face ...</td>\n",
       "      <td>Buried in Trump s bonkers interview with New Y...</td>\n",
       "      <td>April 6, 2017</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hillary Clinton Says Half Her Cabinet Will Be...</td>\n",
       "      <td>Women make up over 50 percent of this country,...</td>\n",
       "      <td>April 26, 2016</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Russian bombing of U.S.-backed forces being di...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. Defense Secretary ...</td>\n",
       "      <td>September 18, 2017</td>\n",
       "      <td>Factual News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Britain says window to restore Northern Irelan...</td>\n",
       "      <td>BELFAST (Reuters) - Northern Ireland s politic...</td>\n",
       "      <td>September 4, 2017</td>\n",
       "      <td>Factual News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "78  HOLLYWEIRD LIB SUSAN SARANDON Compares Muslim ...   \n",
       "52   Elijah Cummings Called Trump Out To His Face ...   \n",
       "4    Hillary Clinton Says Half Her Cabinet Will Be...   \n",
       "20  Russian bombing of U.S.-backed forces being di...   \n",
       "41  Britain says window to restore Northern Irelan...   \n",
       "\n",
       "                                                 text                 date  \\\n",
       "78  There are two small problems with your analogy...         Dec 30, 2015   \n",
       "52  Buried in Trump s bonkers interview with New Y...        April 6, 2017   \n",
       "4   Women make up over 50 percent of this country,...       April 26, 2016   \n",
       "20  WASHINGTON (Reuters) - U.S. Defense Secretary ...  September 18, 2017    \n",
       "41  BELFAST (Reuters) - Northern Ireland s politic...   September 4, 2017    \n",
       "\n",
       "   fake_or_factual  \n",
       "78       Fake News  \n",
       "52       Fake News  \n",
       "4        Fake News  \n",
       "20    Factual News  \n",
       "41    Factual News  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of fake and factual articles\n",
    "data['fake_or_factual'].value_counts().plot(kind='bar', color=default_plot_colour)\n",
    "plt.title('Count of Article Classification')\n",
    "plt.ylabel('# of Articles')\n",
    "plt.xlabel('Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages required for processing and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy import tokenizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import LsiModel, TfidfModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data by fake and factual news\n",
    "fake_news = data[data['fake_or_factual'] == \"Fake News\"]\n",
    "fact_news = data[data['fake_or_factual'] == \"Factual News\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spacey documents - use pipe for dataframe\n",
    "fake_spaceydocs = list(nlp.pipe(fake_news['text']))\n",
    "fact_spaceydocs = list(nlp.pipe(fact_news['text'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to extract tags for each document in our data\n",
    "def extract_token_tags(doc:spacy.tokens.doc.Doc):\n",
    "    return [(i.text, i.ent_type_, i.pos_) for i in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag fake dataset \n",
    "fake_tagsdf = []\n",
    "columns = [\"token\", \"ner_tag\", \"pos_tag\"]\n",
    "\n",
    "for ix, doc in enumerate(fake_spaceydocs):\n",
    "    tags = extract_token_tags(doc)\n",
    "    tags = pd.DataFrame(tags)\n",
    "    tags.columns = columns\n",
    "    fake_tagsdf.append(tags)\n",
    "        \n",
    "fake_tagsdf = pd.concat(fake_tagsdf)   \n",
    "\n",
    "# tag factual dataset \n",
    "fact_tagsdf = []\n",
    "\n",
    "for ix, doc in enumerate(fact_spaceydocs):\n",
    "    tags = extract_token_tags(doc)\n",
    "    tags = pd.DataFrame(tags)\n",
    "    tags.columns = columns\n",
    "    fact_tagsdf.append(tags)\n",
    "        \n",
    "fact_tagsdf = pd.concat(fact_tagsdf)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tagsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token frequency count (fake)\n",
    "pos_counts_fake = fake_tagsdf.groupby(['token','pos_tag']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "pos_counts_fake.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token frequency count (fact)\n",
    "pos_counts_fact = fact_tagsdf.groupby(['token','pos_tag']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "pos_counts_fact.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencies of pos tags\n",
    "pos_counts_fake.groupby(['pos_tag'])['token'].count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_counts_fact.groupby(['pos_tag'])['token'].count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dive into diferences in nouns\n",
    "pos_counts_fake[pos_counts_fake.pos_tag == \"NOUN\"][0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_counts_fact[pos_counts_fact.pos_tag == \"NOUN\"][0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top entities in fake news\n",
    "top_entities_fake = fake_tagsdf[fake_tagsdf['ner_tag'] != \"\"] \\\n",
    "                    .groupby(['token','ner_tag']).size().reset_index(name='counts') \\\n",
    "                    .sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top entities in fact news\n",
    "top_entities_fact = fact_tagsdf[fact_tagsdf['ner_tag'] != \"\"] \\\n",
    "                    .groupby(['token','ner_tag']).size().reset_index(name='counts') \\\n",
    "                    .sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom palette to ensure plots are consistent\n",
    "ner_palette = {\n",
    "    'ORG': sns.color_palette(\"Set2\").as_hex()[0],\n",
    "    'GPE': sns.color_palette(\"Set2\").as_hex()[1],\n",
    "    'NORP': sns.color_palette(\"Set2\").as_hex()[2],\n",
    "    'PERSON': sns.color_palette(\"Set2\").as_hex()[3],\n",
    "    'DATE': sns.color_palette(\"Set2\").as_hex()[4],\n",
    "    'CARDINAL': sns.color_palette(\"Set2\").as_hex()[5],\n",
    "    'PERCENT': sns.color_palette(\"Set2\").as_hex()[6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x = 'counts',\n",
    "    y = 'token',\n",
    "    hue = 'ner_tag',\n",
    "    palette = ner_palette,\n",
    "    data = top_entities_fake[0:10],\n",
    "    orient = 'h',\n",
    "    dodge=False\n",
    ") \\\n",
    ".set(title='Most Common Entities in Fake News')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x = 'counts',\n",
    "    y = 'token',\n",
    "    hue = 'ner_tag',\n",
    "    palette = ner_palette,\n",
    "    data = top_entities_fact[0:10],\n",
    "    orient = 'h',\n",
    "    dodge=False\n",
    ") \\\n",
    ".set(title='Most Common Entities in Factual News')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lot of the factual news has a location tag at the beginning of the article, let's use regex to remove this\n",
    "data['text_clean'] = data.apply(lambda x: re.sub(r\"^[^-]*-\\s*\", \"\", x['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase \n",
    "data['text_clean'] = data['text_clean'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "data['text_clean'] = data.apply(lambda x: re.sub(r\"([^\\w\\s])\", \"\", x['text_clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "en_stopwords = stopwords.words('english')\n",
    "print(en_stopwords) # check this against our most frequent n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_clean'] = data['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (en_stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize \n",
    "data['text_clean'] = data.apply(lambda x: word_tokenize(x['text_clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data[\"text_clean\"] = data[\"text_clean\"].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common unigrams after preprocessing\n",
    "tokens_clean = sum(data['text_clean'], [])\n",
    "unigrams = (pd.Series(nltk.ngrams(tokens_clean, 1)).value_counts()) \n",
    "print(unigrams[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = unigrams.values[:10], \n",
    "            y = unigrams.index[:10], \n",
    "            orient = 'h',\n",
    "            palette=[default_plot_colour])\\\n",
    ".set(title='Most Common Unigrams After Preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common bigrams after preprocessing\n",
    "bigrams = (pd.Series(nltk.ngrams(tokens_clean, 2)).value_counts()) \n",
    "print(bigrams[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use vader so we also get a neutral sentiment count\n",
    "vader_sentiment = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vader_sentiment_score'] = data['text'].apply(lambda review: vader_sentiment.polarity_scores(review)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "bins = [-1, -0.1, 0.1, 1]\n",
    "names = ['negative', 'neutral', 'positive']\n",
    "\n",
    "data['vader_sentiment_label'] = pd.cut(data['vader_sentiment_score'], bins, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vader_sentiment_label'].value_counts().plot.bar(color=default_plot_colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\n",
    "    x = 'fake_or_factual',\n",
    "    hue = 'vader_sentiment_label',\n",
    "    palette = sns.color_palette(\"hls\"),\n",
    "    data = data\n",
    ") \\\n",
    ".set(title='Sentiment by News Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake news data vectorization\n",
    "fake_news_text = data[data['fake_or_factual'] == \"Fake News\"]['text_clean'].reset_index(drop=True)\n",
    "dictionary_fake = corpora.Dictionary(fake_news_text)\n",
    "doc_term_fake = [dictionary_fake.doc2bow(text) for text in fake_news_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate coherence scores to determine an optimum number of topics\n",
    "coherence_values = []\n",
    "model_list = []\n",
    "\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "\n",
    "for num_topics_i in range(min_topics, max_topics+1):\n",
    "    model = gensim.models.LdaModel(doc_term_fake, num_topics=num_topics_i, id2word = dictionary_fake)\n",
    "    model_list.append(model)\n",
    "    coherence_model = CoherenceModel(model=model, texts=fake_news_text, dictionary=dictionary_fake, coherence='c_v')\n",
    "    coherence_values.append(coherence_model.get_coherence())\n",
    "    \n",
    "plt.plot(range(min_topics, max_topics+1), coherence_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lda model\n",
    "num_topics_fake = 5\n",
    "\n",
    "lda_model_fake = gensim.models.LdaModel(corpus=doc_term_fake,\n",
    "                                       id2word=dictionary_fake,\n",
    "                                       num_topics=num_topics_fake)\n",
    "\n",
    "lda_model_fake.print_topics(num_topics=num_topics_fake, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our topics contain a lot of very similar words, let's try using latent semantic anaysis with tf-idf vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF & LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_corpus(doc_term_matrix):\n",
    "    # create a corpus using tfidf vecotization\n",
    "    tfidf = TfidfModel(corpus=doc_term_matrix, normalize=True)\n",
    "    corpus_tfidf = tfidf[doc_term_matrix]\n",
    "    return corpus_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coherence_scores(corpus, dictionary, text, min_topics, max_topics):\n",
    "    # generate coherence scores to determine an optimum number of topics\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics_i in range(min_topics, max_topics+1):\n",
    "        model = LsiModel(corpus, num_topics=num_topics_i, id2word = dictionary)\n",
    "        model_list.append(model)\n",
    "        coherence_model = CoherenceModel(model=model, texts=text, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherence_model.get_coherence())\n",
    "    # plot results\n",
    "    plt.plot(range(min_topics, max_topics+1), coherence_values)\n",
    "    plt.xlabel(\"Number of Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tfidf representation\n",
    "corpus_tfidf_fake = tfidf_corpus(doc_term_fake)\n",
    "# coherence scores for fake news data\n",
    "get_coherence_scores(corpus_tfidf_fake, dictionary_fake, fake_news_text, min_topics=2, max_topics=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for fake news data\n",
    "lsa_fake = LsiModel(corpus_tfidf_fake, id2word=dictionary_fake, num_topics=3)\n",
    "lsa_fake.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict fake or factual news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [','.join(map(str, l)) for l in data['text_clean']]\n",
    "Y = data['fake_or_factual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text vectorization - CountVectorizer\n",
    "countvec = CountVectorizer()\n",
    "countvec_fit = countvec.fit_transform(X)\n",
    "bag_of_words = pd.DataFrame(countvec_fit.toarray(), columns = countvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SGDClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred_svm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
